<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Haque Ishfaq</title>

  <meta name="author" content="Haque Ishfaq">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Haque Ishfaq</name>
              </p>

              <p>
              I am a final year PhD Student at <a href="https://mila.quebec/en/">Mila</a> and <a href="https://www.mcgill.ca/">McGill University</a>, advised by
              Prof. <a href="https://www.cs.mcgill.ca/~dprecup/">Doina Precup</a>. My current research focuses on exploration in reinforcement learning and reinforcement learning with human feedback.
              </p>

              <p> 
                <b>I am on the job market and actively looking for Research Scientist or Postdoctoral Researcher positions in the USA/Canada!</b> 
              </p>

              <p>
              Previously, I obtained my BS (Mathematical and Computational Science) in 2015 and MS (Statistics) in 2018 from
              Stanford University.
              There I am grateful to have my research supervised by Prof. <a href="https://med.stanford.edu/profiles/daniel-rubin">Daniel Rubin</a>. Previously, I also did research internships at Meta AI, Microsoft, IBM Research and Nvidia.
              </p>

              <p>
                Feel free to reach out to me in case you have any questions or want to chat about my work!
              </p>

              <p style="text-align:center">
                <a href="mailto:haque.ishfaq@mail.mcgill.ca">Email</a> &nbsp/&nbsp
                <a href="data/haque-ishfaq-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=W2QQgF8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/hmishfaq">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/HaqueIshfaq">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hmishfaq/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/haque_ishfaq.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/haque_ishfaq.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr><td>
              <heading>News</heading>
              <ul>
                <li><strong>July 2024</strong>: Invited long talk at <a href="https://ismp2024.gerad.ca/">25th International Symposium on Mathematical Programming</a>, Montreal, Canada.</li>
                <li><strong>April 2023</strong>: Invited to attend and present at the Citadel PhD Summit in Miami, USA.</li>
                <li><strong>Summer 2022</strong>: Research internship at Meta AI with Applied Reinforcement Learning Team</li>
                <li><strong>September 2021</strong>: Invited talk at <a href="https://kamyar.page/ml_seminar.html">ML-Seminar</a>, Purdue University. Host: <a href="https://kamyar.page/index.html">Kamyar Azizzadenesheli</a></li>
                <li><strong>September 2021</strong>: Invited talk at Jiantao Jiao Group meeting, University of California, Berkeley. Host: <a href="https://people.eecs.berkeley.edu/~jiantao/">Jiantao Jiao</a></li>
                <li><strong>February 2021</strong>: Invited talk at Benjamin Van Roy Group meeting, Stanford University. Host: <a href="https://web.stanford.edu/~bvr/index.html">Benjamin Van Roy</a></li>
                <li><strong>January 2021</strong>: Contributed talk at  <a href="https://www.microsoft.com/en-us/research/event/reinforcement-learning-day-2021/">Microsoft Research
                  Reinforcement Learning Day 2021</a>.</li>
                <li><strong>November 2020</strong>: Contributed talk at <a href="https://all.cs.umass.edu/nerds2020">Northeast Reinforcement Learning and Decision Making Symposium</a>.</li>
              </ul>
          </td></tr>
      </tbody></table>

      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Conference Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling </papertitle>
              <br>
              <strong>Haque Ishfaq*</strong>,
              <a href="https://openreview.net/profile?id=~Yixin_Tan1">Yixin Tan*</a>,
              <a href="https://openreview.net/profile?id=~Yu_Yang15">Yu Yang</a>,
              <a href="https://lancelqf.github.io/about/">Qingfeng Lan</a>,
              <a href="https://services.math.duke.edu/~jianfeng/">Jianfeng Lu</a>,
              <a href="https://armahmood.github.io/">A. Rupam Mahmood</a>,
              <a href="https://cs.mcgill.ca/~dprecup/">Doina Precup</a> and
              <a href="https://panxulab.github.io/">Pan Xu</a>
              <br>
              <em>Submitted to Reinforcement Learning Conference (RLC)</em>, 2024
              <!-- <br> -->
              <!-- <a href="https://arxiv.org/abs/2403.11574">[Paper]</a> -->
              <!-- <br> -->
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Offline Multitask Representation Learning for Reinforcement Learning </papertitle>
              <br>
              <strong>Haque Ishfaq</strong>,
              <a href="https://thanhnguyentang.github.io/">Thanh Nguyen-Tang</a>,
              <a href="https://openreview.net/profile?id=~Songtao_Feng1">Songtao Feng</a>,
              <a href="https://www.cs.jhu.edu/~raman/Home.html">Raman Arora</a>,
              <a href="https://mwang.princeton.edu/">Mengdi Wang</a>,
              <a href="https://mingyin0312.github.io/">Ming Yin</a> and
              <a href="https://cs.mcgill.ca/~dprecup/">Doina Precup</a>
              <br>
              <em>Submitted to Reinforcement Learning Conference (RLC)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2403.11574">[Paper]</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo </papertitle>
              <br>
              <strong>Haque Ishfaq*</strong>,
              <a href="https://lancelqf.github.io/about/">Qingfeng Lan*</a>,
              <a href="https://panxulab.github.io/">Pan Xu</a>,
              <a href="https://armahmood.github.io/">A. Rupam Mahmood</a>,
              <a href="https://cs.mcgill.ca/~dprecup/">Doina Precup</a>,
              <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a> and
              <a href="https://kamyar.page/">Kamyar Azizzadenesheli</a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2305.18246">[Paper]</a>,
              <a href="https://github.com/hmishfaq/LMC-LSVI">[Code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle> Randomized Exploration for Reinforcement Learning with General Value Function Approximation </papertitle>
              <br>
              <strong>Haque Ishfaq*</strong>,
              <a href="https://qwcui.github.io/">Qiwen Cui*</a>,
              <a href="https://www.cs.toronto.edu/~viet/">Viet Nguyen</a>,
              <a href="https://openreview.net/profile?id=~Alex_Ayoub1">Alex Ayoub</a>,
              <a href="https://zhuoranyang.github.io/">Zhuoran Yang</a>,
              <a href="https://zhaoranwang.github.io/">Zhaoran Wang</a>,
              <a href="https://cs.mcgill.ca/~dprecup/">Doina Precup</a>, and
              <a href="http://drlinyang.net/">Lin F. Yang</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2106.07841">[Paper]</a>
              <br>
            </td>
          </tr>

        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading></heading>
              <heading>Preprints/Workshop Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Randomized Least Squares Policy Optimization</papertitle>
            <br>
            <strong>Haque Ishfaq</strong>,
            Zhuoran Yang,
            Andrei Lupu,
            Viet Nguyen,
            Lewis Liu,
            Riashat Islam,
            Zhaoran Wang and 
            Doina Precup
            <br>
            <em>ICML Workshop on Reinforcement Learning Theory </em>, 2021
            <br>
            <a href="https://lyang36.github.io/icml2021_rltheory/camera_ready/39.pdf">[Paper]</a>
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Path-Based Contextualization of Knowledge Graphs for Textual Entailment</papertitle>
            <br>
            Kshitij Fadnis, 
            Kartik Talamadupula,
            Pavan Kapanipathi,
            <strong>Haque Ishfaq</strong>,
            Salim Roukos and 
            Achille Fokoue
            <br>
            <em>Preprint</em>, 2019
            <br>
            <a href="https://arxiv.org/abs/1911.02085">[Paper]</a>
            <br>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle> TVAE: Triplet-Based Variational Autoencoder using Metric Learning </papertitle>
            <br>
            <strong>Haque Ishfaq</strong>,
            Assaf Hoogi and 
            <a href="https://profiles.stanford.edu/daniel-rubin">Daniel Rubin</a>
            <br>
            <em>Preprint</em>, 2018
            <br>
            <a href="https://arxiv.org/abs/1802.04403">[Paper]</a>
            <br>
          </td>
        </tr>

  </table>
  <p style="text-align:right;">
    <a href="https://jonbarron.info/">Website template</a>
  </p>
</body>

</html>
